{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python",
      "version": "3.8.2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit"
    },
    "interpreter": {
      "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "!\"{sys.executable}\" -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "#Load all libraries\n",
        "\n",
        "# Azure SDK for storage and identity\n",
        "!\"{sys.executable}\" -m pip install azure-storage-blob azure-identity\n",
        "# Data manipulation\n",
        "!\"{sys.executable}\" -m pip install pandas numpy sklearn\n",
        "# Visualization\n",
        "!\"{sys.executable}\" -m pip install matplotlib\n",
        "# Tooling to perform ARIMA forecasts\n",
        "!\"{sys.executable}\" -m pip install pmdarima\n",
        "# Tooling for PySpark\n",
        "!\"{sys.executable}\" -m pip install pyspark\n",
        "# Needed to run the notebook\n",
        "!\"{sys.executable}\" -m pip install jupyter notebook\n",
        "# KQL Magic\n",
        "!\"{sys.executable}\" -m pip install Kqlmagic --no-cache-dir  --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "#credential = DefaultAzureCredential(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "#from azure.storage.blob import BlockBlobService\n",
        "from datetime import datetime, timedelta\n",
        "from azure.storage.blob import BlobServiceClient, generate_account_sas, generate_container_sas, ResourceTypes, AccountSasPermissions, ContainerSasPermissions\n",
        "\n",
        "# Name of the Azure Storage account\n",
        "azure_storage_account = '#STORAGE_ACCOUNT_NAME#'\n",
        "# Name of the Container holding the data\n",
        "azure_storage_container = 'loganalytics'\n",
        "# Base path for the blobs within the container\n",
        "azure_storage_path = ''\n",
        "\n",
        "storage_account_url = \"https://{}.blob.core.windows.net\".format(azure_storage_account)\n",
        "\n",
        "permission = ContainerSasPermissions(read=True, write=True, delete=True, \n",
        "                                 list=True,delete_previous_version=True, tag=True)\n",
        "\n",
        "sas_token = generate_container_sas(\n",
        "    account_name=\"#STORAGE_ACCOUNT_NAME#\",\n",
        "    account_key=\"#STORAGE_ACCOUNT_KEY#\",\n",
        "    container_name=azure_storage_container,\n",
        "    #resource_types=ResourceTypes(container=True),\n",
        "    permission=permission,\n",
        "    expiry=datetime.utcnow() + timedelta(hours=1)\n",
        ")\n",
        "\n",
        "storage_client = BlobServiceClient(account_url=\"https://#STORAGE_ACCOUNT_NAME#.blob.core.windows.net\", credential=sas_token)\n",
        "\n",
        "#block_blob_service = BlockBlobService(account_name='cjgstats', account_key='5/c6LtMdJWfaj9RS8kFGGe179Ug3Bhe3PxngyS4crD7ctrs03M28bvQi3h7CNnAgh8qINcdczXzYMoiAE7mtkA==') \n",
        "\n"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def extract_requests_from_container(client, blob_path, container_name, start_time=None, end_time=None):\n",
        "\n",
        "    container = client.get_container_client(container_name)\n",
        "\n",
        "    blob_list = container.list_blobs(blob_path)\n",
        "\n",
        "    combined_results = []\n",
        "\n",
        "    for blob in blob_list:\n",
        "\n",
        "        body = container.download_blob(blob.name).readall().decode('utf8')\n",
        "\n",
        "        for request_string in body.split('\\n'):\n",
        "            try:\n",
        "                request = json.loads(request_string)\n",
        "                combined_results.append(request)\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                continue\n",
        "    return combined_results\n",
        "\n",
        "data = extract_requests_from_container(storage_client, azure_storage_path, azure_storage_container, \n",
        "datetime.utcnow() - timedelta(hours=3), datetime.utcnow())\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    }
  ]
}